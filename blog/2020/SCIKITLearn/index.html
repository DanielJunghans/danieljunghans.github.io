<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Exploring scikit-learn | Daniel D. Junghans</title>
    <meta name="author" content="Daniel D. Junghans">
    <meta name="description" content="My name is Daniel Junghans and I am a Financial Institution Examiner for Michigan's Department of Insurance and Financial Services. I work within the Office of Banking to protect depositors, creditors, and shareholders. I am a knowledgeable young finance professional eager to leverage my understanding of finance to generate creative solutions. 
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">

    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/al-folio/assets/css/main.css">
    <link rel="canonical" href="https://danieljunghans.github.io/al-folio/blog/2020/SCIKITLearn/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/al-folio/assets/js/theme.js"></script>
    <script src="/al-folio/assets/js/dark_mode.js"></script>
    
  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
<header>

  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="/al-folio/"><span class="font-weight-bold">Daniel </span>D. Junghans</a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/al-folio/">about</a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/al-folio/blog/">blog<span class="sr-only">(current)</span></a>
          </li>

          <!-- Other pages -->
          <li class="nav-item ">
            <a class="nav-link" href="/al-folio/resume/">resume</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/al-folio/projects/">projects</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/al-folio/publications/">publications</a>
          </li>

          <!-- Toogle theme mode -->
          <li class="toggle-container">
            <button id="light-toggle" title="Change theme">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </button>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</header>

    <!-- Content -->
    <div class="container mt-5">
      
        <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Exploring scikit-learn</h1>
    <p class="post-meta">August 28, 2020</p>
    <p class="post-tags">
      <a href="/al-folio/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>
        ·  
        <a href="/al-folio/blog/tag/machine-learning">
          <i class="fas fa-hashtag fa-sm"></i> Machine-Learning</a>  
          

    </p>
  </header>

  <article class="post-content">
    
    <div id="markdown-content">
      <p style="text-align: center;"><font size="+3">Introduction</font></p>
<p>For my current NEAT project, I read the paper <a href="https://ieeexplore.ieee.org/abstract/document/8473214?casa_token=mA1Va18Dm6kAAAAA:v_6_aQSag5JUXPvV3uPm-BYIVUfWLtCD5HZFDXopj5UUDriA460pLKGfCr99nKgQEYCw8a-GAQ" rel="external nofollow noopener" target="_blank"><em>A Comparative Study of Supervised Machine Learning Algorithms for Stock Market Trend Prediction</em></a> to learn  how others approached stock market prediction using supervised machine learning algorithms. This paper compared the accuracy between Support Vector Machine, Random Forest, K-Nearest Neighbor, Naive Bayes, and SoftMax algorithms. After reading about these different algorithms, I took it upon myself to learn more about the scikit-learn python library. I am learning how to use scikit-learn because it will give me the ability to implement some the algorithms outlined in the paper. The algorithms I have covered so far include: <br>
<a href="#RandomForest">•	Random Forest</a><br>
<a href="#KNN">•	K-Nearest Neighbors</a><br>
<a href="#SVM">•	Support Vector Machine</a><br></p>

<p><a name="RandomForest"></a></p>
<p style="text-align: center;"><font size="+3">Random Forest</font></p>
<p>The first algorithm I sought to better understand was the Random Forest algorithm. This algorithm is made up of multiple decision trees. A decision tree learns simple decision rules from the data and produces a output. Each tree is used on a different sub sample of the dataset and averaging is used to improve accuracy. The decision trees all “vote” by producing outputs, and whatever the most popular output is becomes the algorithms output.</p>

<p>I first imported my data as a Pandas data frame and split it up into a training section and a testing section. I then created a Random Forest algorithm using the scikit-learn random forest classifier. After running the algorithm a few times, I noticed that the accuracy was unusually high. After some investigation, I discovered that the algorithms were predicting the stock price movement for the current day instead of one day in the future. After fixing the problem, the accuracy on the testing dataset stayed around 50%. Here is the code that I wrote:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td>
<td class="code"><pre><span class="kn">import</span> <span class="n">csv</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="c1">#this opens the file and puts the data in a pandas dataframe
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">RandomForest.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1">#setting the size of the training dataset
</span><span class="n">training_size</span> <span class="o">=</span> <span class="p">.</span><span class="mi">7</span>
<span class="n">split</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="p">.</span><span class="mi">7</span><span class="p">)</span>

<span class="c1">#Identifying all of the inputs and the expected output
</span><span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">[[</span><span class="sh">'</span><span class="s">Open</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Close</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Accumulation Distribution Line</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">MACD</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Chaikan Oscillator (CHO)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Highest closing price (5 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Lowest closing price (days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Stochastic %K (5 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">%D</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume Price Trend (VPT)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Williams %R (14 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Relative Strength Index</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Momentum (10 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Price rate of change (PROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume rate of change (VROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">On Balance Volume (OBV)</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">Outputs</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">#splitting the dataframe into a training and testing dataset
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>

<span class="c1">#create a the random forest with 500 decision trees
</span><span class="n">clf</span><span class="o">=</span><span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span> 

<span class="c1">#train the model on the training data
</span><span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#making predictions on the testing data
</span><span class="n">y_pred</span><span class="o">=</span><span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#printing the testing accuracy
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Accuracy:</span><span class="sh">"</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></td>
</tr></tbody></table></code></pre></figure>

<p><a name="KNN"></a></p>
<p style="text-align: center;"><font size="+3">K-Nearest Neighbors</font></p>
<p>The next algorithm I studied was the K-Nearest Neighbors algorithm. The nearest neighbor method looks for the most similar trading days. The predefined number of the most similar trading days become the nearest neighbors. Just like the decision trees in the Random Forest algorithm, the nearest neighbors “vote”. Instead of using decision trees to produce an output, the K-Nearest Neighbor algorithm uses the actual expected output for the most similar trading days. The most popular output becomes of the neighbors becomes the algorithms output. If 5 of the nearest neighbors had the closing stock price go up and 3 neighbors had the stock price go down, the prediction will be that the stock price goes up.</p>

<p>While studying this algorithm, I learned that K-Nearest Neighbor algorithms performs better with a lower number of features/inputs. To reduce the size of my dataset, I first normalized it with the standard scaler tool from scikit-learn. I then used PCA to shrink the number of inputs in my dataset down to two while preserving the variance in the dataset.  Here is my K-Nearest Neighbors code:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
</pre></td>
<td class="code"><pre><span class="kn">import</span> <span class="n">csv</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1">#this opens the CSV File
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">RandomForest.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1">#preprocessing and normalizing
</span><span class="n">Features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Open</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Close</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Accumulation Distribution Line</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">MACD</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Chaikan Oscillator (CHO)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Highest closing price (5 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Lowest closing price (days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Stochastic %K (5 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">%D</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume Price Trend (VPT)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Williams %R (14 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Relative Strength Index</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Momentum (10 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Price rate of change (PROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume rate of change (VROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">On Balance Volume (OBV)</span><span class="sh">'</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Features</span><span class="p">].</span><span class="n">values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="sh">'</span><span class="s">Outputs</span><span class="sh">'</span><span class="p">]].</span><span class="n">values</span>

<span class="c1">#normalizing the dataset
</span><span class="n">X</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#performing PCA
</span><span class="n">PCA</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">Components</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">ComponentDf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">Components</span><span class="p">)</span>

<span class="c1">#setting the size of the training set
</span><span class="n">training_size</span> <span class="o">=</span> <span class="p">.</span><span class="mi">8</span>
<span class="n">split</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="n">training_size</span><span class="p">)</span>

<span class="c1">#splitting up the dataset
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ComponentDf</span><span class="p">[:</span><span class="n">split</span><span class="p">])</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ComponentDf</span><span class="p">[</span><span class="n">split</span><span class="p">:])</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">Y</span><span class="p">[:</span><span class="n">split</span><span class="p">])</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">Y</span><span class="p">[</span><span class="n">split</span><span class="p">:])</span>

<span class="c1">#create the K Nearest Neighbor Algorithm and running the algorithm
</span><span class="n">clf</span><span class="o">=</span><span class="nc">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">ravel</span><span class="p">())</span>
<span class="n">Y_pred</span><span class="o">=</span><span class="n">clf</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#printing the testing accuracy 
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Accuracy:</span><span class="sh">"</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
</pre></td>
</tr></tbody></table></code></pre></figure>

<p>After performing principal component analysis on my dataset, I graphed the principal components to better understand the data. After creating the graph, it became clear why the accuracy of my K-Nearest Neighbor algorithm stayed around 50%. Both expected outputs (Stock price going up or down) are clustered together.</p>

<div class="img">
    <img class="col three" src="/al-folio/assets/img/Component.PNG">
</div>

<p><a name="SVM"></a></p>
<p style="text-align: center;"><font size="+3">Support Vector Machine</font></p>
<p>A Support Vector Machine is a machine learning tool that uses a hyperplane to define data points. Instead of looking at the nearest neighbors like a KNN, I like to think that Support Vector Machines split up data points into different neighborhoods. For example, if we use the two components from my PCA analysis, a SVM will create a one dimensional hyperplane splitting up the data into two “neighborhoods”. The hyperplane will create decision boundaries that maximize the margins from both expected outputs. The graph below shows the data points and the decision boundaries created by my SVM.</p>

<div class="img">
    <img class="col three" src="/al-folio/assets/img/graph10.png">
</div>

<p>Any data point that falls into the blue background gets categorized as a 0 (closing stock price goes down). To create this graph, I used a Support Vector Machine with a RBF kernel. Kernel functions allow SVMs to create hyperplanes in high dimensional data without having to calculate the coordinates of the data in that space. Here is my Support Vector Machine Code:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
</pre></td>
<td class="code"><pre><span class="c1">#support vector machine
</span>
<span class="kn">import</span> <span class="n">csv</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1">#this opens the CSV File
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">RandomForest.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1">#setting the size of the training dataset
</span><span class="n">training_size</span> <span class="o">=</span> <span class="p">.</span><span class="mi">7</span>
<span class="n">split</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">*</span><span class="p">.</span><span class="mi">7</span><span class="p">)</span>

<span class="c1">#Identifying all of the inputs and the expected output
</span><span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">[[</span><span class="sh">'</span><span class="s">Open</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">High</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Low</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Close</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Accumulation Distribution Line</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">MACD</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Chaikan Oscillator (CHO)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Highest closing price (5 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Lowest closing price (days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Stochastic %K (5 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">%D</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume Price Trend (VPT)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Williams %R (14 days)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Relative Strength Index</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Momentum (10 days)</span><span class="sh">'</span><span class="p">,</span>
<span class="sh">'</span><span class="s">Price rate of change (PROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">Volume rate of change (VROC)</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">On Balance Volume (OBV)</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">y</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">Outputs</span><span class="sh">'</span><span class="p">]</span>

<span class="c1">#splitting the dataframe into a training and testing dataset
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">split</span><span class="p">:]</span>

<span class="c1">#create the support vector machine
</span><span class="n">svc</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">svc</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#printing the testing accuracy
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Accuracy:</span><span class="sh">"</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1">##################################################
#The next section transforms the dataset#
#And graphs the components with decision boundries
</span>
<span class="c1">#Normalizing the dataset
</span><span class="n">X</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">().</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#performing PCA
</span><span class="n">PCA</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">Components</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">ComponentDf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">Components</span><span class="p">,</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">principal component 1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">principal component 2</span><span class="sh">'</span><span class="p">])</span>

<span class="c1">#transforming the dataset
</span><span class="n">X</span> <span class="o">=</span> <span class="n">ComponentDf</span><span class="p">.</span><span class="nf">to_numpy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()</span>

<span class="n">h</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># create a mesh to plot in
</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span>
                     <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>

<span class="c1">#create the support vector machine
</span><span class="n">svc</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="nc">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="sh">'</span><span class="s">rbf</span><span class="sh">'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">).</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">#graphing the data
</span><span class="n">Z</span> <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="p">.</span><span class="nf">ravel</span><span class="p">()])</span>

<span class="c1"># Put the result into a color plot
</span><span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">xx</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">coolwarm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># Creating the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">coolwarm</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Principal Component 1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Principal Component 2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">(</span><span class="n">xx</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">xx</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="n">yy</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">yy</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(())</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Support Vector Machine Graph</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

<span class="c1"># Saving the Plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">"</span><span class="s">matplotlib.png</span><span class="sh">"</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></figure>

    </div>
  </article>


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2023/LiquidityTrends/">Ongoing Liquidity Trends for Michigan Banks</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2023/Liquidity/">Liquidity Determinants of Michigan Banks</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2020/Reflection/">2020 Summer Reflection</a>
  </li>

  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/al-folio/blog/2020/NEAT/">NEAT Project</a>
  </li>
</div>
      
    </div>

    <!-- Footer -->
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2023 Daniel D. Junghans. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

  </div>
</footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
    <!-- Bootsrap & MDB scripts -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
    <!-- Masonry & imagesLoaded -->
<script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/al-folio/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/al-folio/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/al-folio/assets/js/no_defer.js"></script>
  <script defer src="/al-folio/assets/js/common.js"></script>
  <script defer src="/al-folio/assets/js/copy_code.js" type="text/javascript"></script>
    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>
    <!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </body>
</html>
